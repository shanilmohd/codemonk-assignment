{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 329006,
          "sourceType": "datasetVersion",
          "datasetId": 139630
        },
        {
          "sourceId": 70394,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 58768
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "fashion-classification",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'fashion-product-images-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F139630%2F329006%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240628%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240628T203447Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0f17450769d54defbd574cbfa6c35ea5c69b69545e041fb19dae864d189c557070ff1047f4bc217a486bfc5a405e219ff3c5d276d3c2e753a225a8a6ade1c569d4912a42e0190ea9512fdfc0e3ab5d35c196ca6f9be9b0ce7129830186d772c0d3a79be64ea4bcdbdb643b13f072cec24e90ab1c0c84e03fcd1d89f0f501ee56f739b58468b87b13ddb5cde47d944c0d91a3c1ec6c5aa81bbad1d2a4d520a8b63736be4ece1a0f8dc70150703b9f3b35db079118f4a25e44146e09317ff51e553c628448983b45f5a251fd57d2ec5869135894ab6ee074214cf88852b85388132da8e9e3ce76d023a893e60eaa580410875da83e7b8f18b3d0f9c1119650a977,model-fashion/tensorflow2/model-fashion/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F58768%2F70394%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240628%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240628T203447Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7f77158db7fdb3c277fe4ad1d00b5304e2d43917ad998760d5315ca82d47e6e644d9eb9e1af7b572370d415603522eebfae0c7a6f00cc3785641cfdfda3273affc77f6579248af5e3ea00858f972171cadb7aa581b5dfa95fac64fa132279233249fe5256a4693fc1ccc78322150cecfbd3baf8c1620ed4444aae55450c4421e30fbf78ec8469df524233af705a34d4dca8bcc56ea1dbe418eb215b5ad138d6aeaa8c058c5533d533a11eb3127b97364ba613f6b8835f7d747598b31a29a4d9552d3025e95974985b3aaf97109b92a770dccbf9e21020176eaeddd6554c07317aef7c235882c3d14711d288f7a1b1251e766252b804ddd7613f589f14a2dba5f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "RbzO3fRPjs3p"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "COOp06Oxjs3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Flatten)\n",
        "from tensorflow.keras.layers import (Dense, Lambda, Dropout, Activation)\n",
        "\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D)\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YwTkbjH8js3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STYLES_CSV_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/styles.csv\"\n",
        "IMAGES_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/images/\""
      ],
      "metadata": {
        "id": "bIuHFrJcjs3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(STYLES_CSV_PATH, error_bad_lines = False, warn_bad_lines=False)\n",
        "print(f\"Total Rows: {df.shape[0]}\\nTotal Columns: {df.shape[1]}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gMy-DY_bjs3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('NaN Count:')\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "eG_DBC_9js3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df = df.drop(['year', 'productDisplayName', 'masterCategory', 'subCategory','usage'], axis=1)\n",
        "\n",
        "df = df[df['id'].isin([int(i.split('.')[0]) for i in os.listdir(IMAGES_PATH)])]"
      ],
      "metadata": {
        "id": "izTHK0RWjs3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have grouped similar color and article types. This reduces the number of classes and can be effective for imbalance"
      ],
      "metadata": {
        "id": "5OexvWWHjs3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "\n",
        "\n",
        "df = df.drop(df[df['gender'] == 'Boys'].index)\n",
        "df = df.drop(df[df['gender'] == 'Girls'].index)\n",
        "article_mapping = {\n",
        "    'Clothing': ['Tshirts', 'Shirts', 'Kurtas', 'Tops', 'Briefs', 'Jeans', 'Trousers', 'Bra', 'Shorts', 'Sarees', 'Dresses', 'Track Pants', 'Sweatshirts', 'Sweaters', 'Jackets', 'Kurtis', 'Innerwear Vests', 'Tunics', 'Nightdress', 'Leggings', 'Night suits', 'Trunk', 'Capris', 'Skirts', 'Kurta Sets', 'Lounge Pants', 'Boxers'],\n",
        "    'Footwear': ['Casual Shoes', 'Sports Shoes', 'Heels', 'Flip Flops', 'Sandals', 'Formal Shoes', 'Flats', 'Sports Sandals'],\n",
        "    'Accessories': ['Watches', 'Handbags', 'Sunglasses', 'Wallets', 'Belts', 'Backpacks', 'Socks', 'Earrings', 'Clutches', 'Caps', 'Pendant', 'Necklace and Chains', 'Scarves', 'Ring', 'Dupatta', 'Cufflinks', 'Accessory Gift Set', 'Stoles', 'Duffel Bag', 'Bangle', 'Laptop Bag', 'Bracelet', 'Jewellery Set'],\n",
        "    'Personal Care': ['Perfume and Body Mist', 'Deodorant', 'Nail Polish', 'Lipstick', 'Lip Gloss', 'Kajal and Eyeliner', 'Foundation and Primer', 'Fragrance Gift Set'],\n",
        "    'Other': ['Other', 'Free Gifts']\n",
        "}\n",
        "\n",
        "color_mapping = {\n",
        "    'Black': ['Black', 'Charcoal'],\n",
        "     'Grey': [ 'Grey', 'Steel', 'Grey Melange'],\n",
        "    'White': ['White', 'Off White', 'Cream', 'Beige', 'Tan'],\n",
        "    'Blue': ['Blue', 'Navy Blue', 'Turquoise Blue', 'Teal'],\n",
        "    'Red': ['Red', 'Maroon', 'Rust'],\n",
        "    'Pink': ['Pink', 'Purple', 'Lavender', 'Magenta'],\n",
        "    'Purple': ['Purple', 'Lavender'],\n",
        "    'Green': ['Green', 'Olive'],\n",
        "    'Yellow': ['Yellow', 'Mustard', 'Gold'],\n",
        "    'Orange':['Orange'],\n",
        "    'Brown': ['Brown', 'Bronze', 'Copper'],\n",
        "    'Other Colors': ['Silver', 'Multi', 'Other', 'Peach', 'Skin', 'Khaki']\n",
        "}\n",
        "\n",
        "# Apply the mapping to the articleType column\n",
        "\n",
        "color_reverse_mapping = {item: key for key, values in color_mapping.items() for item in values}\n",
        "article_reverse_mapping = {item: key for key, values in article_mapping.items() for item in values}\n",
        "\n",
        "# Apply the mapping to the baseColour column\n",
        "df['baseColour'] = df['baseColour'].map(color_reverse_mapping).fillna(df['baseColour'])\n",
        "df['articleType'] = df['articleType'].map(article_reverse_mapping).fillna(df['articleType'])\n",
        "\n",
        "# catcounts=pd.value_counts(df['gender'])\n",
        "# print(catcounts)\n",
        "catcounts=pd.value_counts(df['articleType'])\n",
        "print(catcounts)\n",
        "# for i in catcounts:\n",
        "#     print(i)\n",
        "\n",
        "catcounts=pd.value_counts(df['baseColour'])\n",
        "print(catcounts)\n",
        "# catcounts=pd.value_counts(df['season'])\n",
        "# print(catcounts)\n"
      ],
      "metadata": {
        "id": "R9T10oq4js3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['id'] = df['id'].apply(lambda x: IMAGES_PATH+str(x) +'.jpg')\n",
        "\n",
        "image_ids = df.pop('id')\n"
      ],
      "metadata": {
        "id": "-4U8Tynsjs3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_ids)"
      ],
      "metadata": {
        "id": "8Xop4Fwyjs3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "\n",
        "IMAGE_DIMS = (60, 60, 3)\n",
        "\n",
        "def load_image(imagePath):\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "image_data = []\n",
        "for img_path in tqdm(image_ids):\n",
        "    image_data.append(load_image(img_path))\n",
        "image_data = np.array(image_data, dtype=\"float\")"
      ],
      "metadata": {
        "id": "-S0Kt3kAjs3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articleTypeLB = LabelBinarizer()\n",
        "genderLB = LabelBinarizer()\n",
        "baseColourLB = LabelBinarizer()\n",
        "seasonLB = LabelBinarizer()\n",
        "\n",
        "\n",
        "articleTypeLabels = articleTypeLB.fit_transform(np.array(df['articleType'].values))\n",
        "genderLabels = genderLB.fit_transform(np.array(df['gender'].values))\n",
        "baseColourLabels = baseColourLB.fit_transform(np.array(df['baseColour'].values))\n",
        "seasonLabels = seasonLB.fit_transform(np.array(df['season'].values))\n",
        "\n",
        "\n",
        "\n",
        "split = train_test_split(image_data,\n",
        "                         articleTypeLabels,\n",
        "                         genderLabels,\n",
        "                         baseColourLabels,\n",
        "                         seasonLabels,\n",
        "                         test_size=0.3, random_state=42)\n",
        "\n",
        "(trainX, testX,\n",
        " trainArticleTypeY, testArticleTypeY,\n",
        " trainGenderY, testGenderY,\n",
        " trainBaseColourY, testBaseColourY,\n",
        " trainSeasonY, testSeasonY) = split"
      ],
      "metadata": {
        "id": "Nnde1yC0js3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used class weight method as a solution for the class imbalance. The class weight method involves assigning different weights to different classes to counteract the imbalance. During model training, these weights adjust the loss function, so that misclassifying a minority class instance will have a higher penalty than misclassifying a majority class instance. This encourages the model to pay more attention to the minority classes, improving their classification performance."
      ],
      "metadata": {
        "id": "HegH1iczjs3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "color_class_weights = compute_class_weight('balanced', classes=np.unique(df['baseColour']), y=df['baseColour'])\n",
        "type_class_weights = compute_class_weight('balanced', classes=np.unique(df['articleType']), y=df['articleType'])\n",
        "season_class_weights = compute_class_weight('balanced', classes=np.unique(df['season']), y=df['season'])\n",
        "gender_class_weights = compute_class_weight('balanced', classes=np.unique(df['gender']), y=df['gender'])\n",
        "\n",
        "color_class_weights = {i: weight for i, weight in enumerate(color_class_weights)}\n",
        "type_class_weights = {i: weight for i, weight in enumerate(type_class_weights)}\n",
        "season_class_weights = {i: weight for i, weight in enumerate(season_class_weights)}\n",
        "gender_class_weights = {i: weight for i, weight in enumerate(gender_class_weights)}\n"
      ],
      "metadata": {
        "id": "Qgu_Uapmjs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "hmCV9OZ3js3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_branch(res_input, n_out, act_type, name):\n",
        "    z = Dense(512, activation=\"relu\")(res_input)\n",
        "    z = Dense(256, activation='relu')(z)\n",
        "    z = Dense(128, activation='relu')(z)\n",
        "    z = Dense(n_out)(z)\n",
        "    z = Activation(act_type, name=name+'_output')(z)\n",
        "    return z"
      ],
      "metadata": {
        "id": "-Obkt8Tljs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(width, height):\n",
        "\n",
        "    # -------------------------\n",
        "    res50 = ResNet50(weights='imagenet', include_top=False, input_shape=IMAGE_DIMS)\n",
        "    res50.trainable=False\n",
        "    inputs = Input(shape=IMAGE_DIMS)\n",
        "    x = res50(inputs, training=False)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    # -------------------------\n",
        "\n",
        "    article_branch = make_branch(x, len(articleTypeLB.classes_), 'softmax', 'article')\n",
        "    gender_branch = make_branch(x, len(genderLB.classes_), 'softmax', 'gender')\n",
        "    color_branch = make_branch(x, len(baseColourLB.classes_), 'softmax', 'color')\n",
        "    season_branch = make_branch(x, len(seasonLB.classes_), 'softmax', 'season')\n",
        "\n",
        "    model = Model(inputs=inputs,\n",
        "                outputs=[article_branch, gender_branch, color_branch,\n",
        "                            season_branch])\n",
        "    return model"
      ],
      "metadata": {
        "id": "TK5zwGB4js3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(60, 60)\n",
        "\n",
        "losses = {\n",
        "    \"article_output\": \"categorical_crossentropy\",\n",
        "    \"gender_output\": \"categorical_crossentropy\",\n",
        "    \"color_output\": \"categorical_crossentropy\",\n",
        "    \"season_output\": \"categorical_crossentropy\"\n",
        "}\n",
        "\n",
        "EPOCHS = 25\n",
        "INIT_LR = 1e-5\n",
        "BS = 32\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(optimizer=opt, loss=losses, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "apbyuoeijs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)\n",
        "class_weight = {\n",
        "    'color_output': color_class_weights,\n",
        "    'article_output': type_class_weights,\n",
        "    'season_output': season_class_weights,\n",
        "    'gender_output': gender_class_weights\n",
        "}"
      ],
      "metadata": {
        "id": "vKLKG2AVjs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(trainX,\n",
        "    {\"article_output\": trainArticleTypeY,\n",
        "    \"gender_output\": trainGenderY,\n",
        "    \"color_output\": trainBaseColourY,\n",
        "    \"season_output\": trainSeasonY},\n",
        "    validation_data=(testX,\n",
        "    {\"article_output\": testArticleTypeY,\n",
        "    \"gender_output\": testGenderY,\n",
        "    \"color_output\": testBaseColourY,\n",
        "    \"season_output\": testSeasonY}),\n",
        "    epochs=100,\n",
        "    batch_size=BS,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "ZskMTdanjs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.evaluate(testX,\n",
        "    {\"article_output\": testArticleTypeY,\n",
        "    \"gender_output\": testGenderY,\n",
        "    \"color_output\": testBaseColourY,\n",
        "    \"season_output\": testSeasonY}, batch_size=32, verbose=0)\n",
        "print('loss', res[:6])\n",
        "print('acc', list(map(lambda x: round(x*100,2), res[6:])))"
      ],
      "metadata": {
        "id": "KtiyPwIKjs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inference on test-data-set\n",
        "idx=130\n",
        "\n",
        "(categoryProba, genderProba, colorProba, seasonProba) = model.predict(np.expand_dims(testX[idx], axis=0))\n",
        "\n",
        "categoryIdx = categoryProba[0].argmax()\n",
        "genderIdx = genderProba[0].argmax()\n",
        "colorIdx = colorProba[0].argmax()\n",
        "seasonIdx = seasonProba[0].argmax()\n",
        "\n",
        "categoryLabel = articleTypeLB.classes_[categoryIdx]\n",
        "genderLabel = genderLB.classes_[genderIdx]\n",
        "colorLabel = baseColourLB.classes_[colorIdx]\n",
        "seasonLabel = seasonLB.classes_[seasonIdx]\n",
        "\n",
        "\n",
        "categoryText = \"Category: {} ({:.2f}%)\".format(categoryLabel, categoryProba[0][categoryIdx] * 100)\n",
        "genderText = \"Gender: {} ({:.2f}%)\".format(genderLabel, genderProba[0][genderIdx] * 100)\n",
        "colorText = \"Color: {} ({:.2f}%)\".format(colorLabel, colorProba[0][colorIdx] * 100)\n",
        "seasonText = \"Season: {} ({:.2f}%)\".format(seasonLabel, seasonProba[0][seasonIdx] * 100)\n",
        "\n",
        "\n",
        "print(categoryText, '-----', articleTypeLB.classes_[testArticleTypeY[idx].argmax()])\n",
        "print(genderText, '-----',genderLB.classes_[testGenderY[idx].argmax()])\n",
        "print(colorText, '-----',baseColourLB.classes_[testBaseColourY[idx].argmax()])\n",
        "print(seasonText, '-----',seasonLB.classes_[testSeasonY[idx].argmax()])\n"
      ],
      "metadata": {
        "id": "7KHulkhfjs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/kaggle/working/multi_output_model.h5')"
      ],
      "metadata": {
        "id": "_KEnZUZ7js3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inference on external data\n",
        "from keras.applications.resnet import preprocess_input\n",
        "IMAGE_DIMS = (60, 60, 3)\n",
        "\n",
        "def load_image_inference(imagePath):\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "#model loading\n",
        "model = tf.keras.models.load_model('/kaggle/input/model-fashion/tensorflow2/model-fashion/1/multi_output_model.h5')\n",
        "#image loading\n",
        "(categoryProba, genderProba, ageProba, colorProba) = model.predict(np.expand_dims(load_image_inference(\"/kaggle/input/test-image/image_1.jpeg\"), axis=0))\n",
        "\n",
        "categoryIdx = categoryProba[0].argmax()\n",
        "genderIdx = genderProba[0].argmax()\n",
        "ageIdx = ageProba[0].argmax()\n",
        "colorIdx = colorProba[0].argmax()\n",
        "\n",
        "categoryLabel = articleTypeLB.classes_[categoryIdx]\n",
        "genderLabel = genderLB.classes_[genderIdx]\n",
        "ageLabel = baseColourLB.classes_[ageIdx]\n",
        "colorLabel = seasonLB.classes_[colorIdx]\n",
        "\n",
        "\n",
        "categoryText = \"Category: {} ({:.2f}%)\".format(categoryLabel, categoryProba[0][categoryIdx] * 100)\n",
        "genderText = \"Gender: {} ({:.2f}%)\".format(genderLabel, genderProba[0][genderIdx] * 100)\n",
        "ageText = \"Age: {} ({:.2f}%)\".format(ageLabel, ageProba[0][ageIdx] * 100)\n",
        "colorText = \"Color: {} ({:.2f}%)\".format(colorLabel, colorProba[0][colorIdx] * 100)\n",
        "\n",
        "\n",
        "print(categoryText, '-----', articleTypeLB.classes_[testArticleTypeY[idx].argmax()])\n",
        "print(genderText, '-----',genderLB.classes_[testGenderY[idx].argmax()])\n",
        "print(ageText, '-----',baseColourLB.classes_[testBaseColourY[idx].argmax()])\n",
        "print(colorText, '-----',seasonLB.classes_[testSeasonY[idx].argmax()])"
      ],
      "metadata": {
        "id": "gcicY-iVjs3u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}